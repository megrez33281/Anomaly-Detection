# HW2 Anomaly Detection - 問題回答

### Q1. Explain your implementation which get the best performance in detail.

*(初步草稿，待實驗完成後更新)*

我們的最佳性能模型是一個基於 U-Net 架構的卷積自編碼器（Convolutional Autoencoder），並結合了多項優化策略以達到最佳效果：

1.  **核心架構 (U-Net Autoencoder)**: 我們採用了 U-Net 型的自編碼器。相比傳統的 Autoencoder，U-Net 的跳接（Skip Connections）允許解碼器直接獲取來自編碼器對應層級的特徵，這使得模型能夠同時捕捉全局語義信息和局部紋理細節，對於重建高清工業圖像至關重要，能有效避免重建圖像過於模糊的問題。

2.  **複合損失函數 (MSE + SSIM)**: 為了提升重建品質，我們沒有使用單純的均方誤差（MSE）損失，而是結合了 MSE 和結構相似性指數（SSIM）。
    *   **MSE Loss**: 保證像素級別的重建準確性。
    *   **SSIM Loss**: 衡量重建圖像與原圖在亮度、對比度和結構上的相似性，迫使模型學習到更真實的紋理和邊緣。我們使用的損失函數為 `L = MSE + λ * (1 - SSIM)`，其中 `λ` 是一個超參數（根據計畫書，設為0.84），用於平衡兩者的重要性。

3.  **偽異常驗證 (CutPaste Augmentation)**: 由於訓練集中只包含正常樣本，我們使用 CutPaste 方法來創建一個可靠的驗證集。具體做法是從正常圖像中隨機剪切一塊，粘貼到圖像的另一位置，生成「偽異常」樣本。我們利用這個驗證集計算 AUROC，作為模型選擇和早期停止（Early Stopping）的依據，有效防止了模型在訓練集上的過擬合。

4.  **多尺度推論 (Multi-Scale Inference)**: 為了檢測不同大小的異常（例如微小刮痕與大面積污漬），我們在推論階段採用了多尺度滑窗策略。同一個模型在多個尺度（例如 128x128, 256x256）的滑窗上對測試圖像進行重建，並計算每個 Patch 的重建誤差。

5.  **異常分數計算 (Top-k Anomaly Score)**: 多尺度誤差圖譜經過標準化和合併後，我們不直接取全局平均誤差（這會稀釋異常信號），而是取誤差最大的前 k% 的像素點計算平均值，作為最終的異常分數。這種 Top-k 策略能顯著放大局部異常，提升檢測的靈敏度。

---

### Q2. Explain the rationale for using auc score instead of F1 score for binary classification in this homework.

在異常檢測這類任務中，使用 AUC (Area Under the ROC Curve) 分數作為評估指標通常比 F1 分數更為合理，主要原因如下：

1.  **極度不平衡的數據集 (Highly Imbalanced Dataset)**: 異常檢測的本質決定了數據集是極度不平衡的——正常樣本（負類）的數量遠遠多於異常樣本（正類）。在這種情況下，F1 分數會受到分類閾值（Threshold）的劇烈影響。只要稍微移動閾值，觸發一些樣本的預測標籤從「正常」變為「異常」（或反之），就會導致召回率（Recall）和精確率（Precision）發生巨大變化，從而使 F1 分數不穩定。

2.  **AUC 的閾值無關性 (Threshold-Independent)**: AUC 衡量的是模型在所有可能的分類閾值下，將正樣本排在負樣本前面的總體能力。它評估的是模型的「排序」品質，而不是在某個特定閾值下的「分類」表現。對於異常檢測，我們更關心的是模型能否穩定地給異常樣本打出比正常樣本更高的「異常分數」，而 AUC 正好能衡量這一點，它不依賴於我們最終選擇哪個閾值來劃分正常/異常。

3.  **任務目標的契合度**: 在很多實際應用中（如醫療診斷、金融詐欺偵測），我們不僅僅是想得到一個分類結果，更希望得到一個風險排序。AUC 正好反映了這種排序能力。一個高 AUC 的模型意味著我們可以自信地將得分最高的樣本標記為「高度可疑」，即使我們還沒有確定最佳的分類切分點。

總結來說，對於異常檢測這種樣本不平衡且關心異常排序的任務，AUC 提供了一個更全面、更穩定且與閾值選擇無關的評估，比 F1 分數更能反映模型的真實性能。

---

### Q3. Discuss the difference between semi-supervised learning and unsupervised learning.

無監督學習（Unsupervised Learning）和半監督學習（Semi-supervised Learning）都處理包含未標註數據的場景，但它們的目標和假設有著本質的區別。

**1. 無監督學習 (Unsupervised Learning):**
*   **數據**: 訓練數據**完全沒有**任何標籤。例如，聚類（Clustering）、降維（Dimensionality Reduction）和密度估計（Density Estimation）都是典型的無監督學習任務。
*   **目標**: 探索數據內在的結構、模式或分佈。模型試圖在沒有任何先驗知識的情況下，自動從數據中發現有趣的規律。例如，將相似的數據點分到同一組（聚類），或者學習數據的緊湊表示（自編碼器）。
*   **本次作業的關聯**: 如果我們只使用正常訓練樣本來學習一個「正常」數據的分佈模型（例如高斯混合模型或 Autoencoder），並且在測試時將那些不符合這個分佈的樣本視為異常，那麼這個過程本質上是無監督的，因為我們從未利用任何關於「異常」這個類別的標籤信息。

**2. 半監督學習 (Semi-supervised Learning):**
*   **數據**: 訓練數據包含**一小部分有標籤的數據**和**大量無標籤的數據**。
*   **目標**: 利用大量無標籤數據的內在結構，來提升在少量有標籤數據上學習到的模型的泛化能力。其核心假設是：數據的分佈（無論是否有標籤）能夠為學習決策邊界提供有用的信息。例如，如果兩個點在一個高密度區域內很接近，那麼它們的標籤很可能是相同的。
*   **本次作業的關聯**: 本次作業的場景更精確地說，可以被看作是半監督學習的一個特例，有時被稱為「單類半監督學習」或「PU學習」（Learning from Positive and Unlabeled data）。在我們的設定中：
    *   訓練集裡的「正常」樣本可以被視為帶有「正常」標籤的數據（即正類，Positive）。
    *   測試集裡的數據則是未標註的（Unlabeled），裡面混雜了正常（Positive）和異常（Negative）樣本。
    我們利用有標籤的正常數據學習一個模型，然後用這個模型去區分未標註數據中的兩種不同類別。因此，它符合半監督學習「利用有標籤數據指導對無標籤數據的理解」這一特徵。

**核心差異總結:**

| 特徵 | 無監督學習 | 半監督學習 |
| :--- | :--- | :--- |
| **訓練數據** | 100% 無標籤 | 小部分有標籤 + 大量無標籤 |
| **學習目標** | 發現數據內在結構 | 提升在有標籤數據上的分類/回歸性能 |
| **核心思想** | 數據探索與表示 | 利用無標籤數據輔助有標籤數據的學習 |
| **與本次作業關係** | 學習「正常」分佈，可視為無監督 | 利用「正常」標籤來預測「未標註」數據，更接近半監督特例 |
